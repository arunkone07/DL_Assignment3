{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8271978,"sourceType":"datasetVersion","datasetId":4911413}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"name":"Fork of DL_Ass3 45bfe0","provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport random\nimport wandb\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nimport seaborn as sns\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"TQsbGdSWB3he","execution":{"iopub.status.busy":"2024-05-17T17:13:48.430591Z","iopub.execute_input":"2024-05-17T17:13:48.430996Z","iopub.status.idle":"2024-05-17T17:13:55.546057Z","shell.execute_reply.started":"2024-05-17T17:13:48.430962Z","shell.execute_reply":"2024-05-17T17:13:55.545270Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"wandb.login()\n# 3dc8367198d0460ba99efb94e713de7e299e685d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S45OXo-zB3hg","outputId":"b893476a-6b41-44d4-86ca-413f08284e0c","execution":{"iopub.status.busy":"2024-05-17T17:13:55.547727Z","iopub.execute_input":"2024-05-17T17:13:55.548183Z","iopub.status.idle":"2024-05-17T17:14:00.254339Z","shell.execute_reply.started":"2024-05-17T17:13:55.548157Z","shell.execute_reply":"2024-05-17T17:14:00.253415Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'\n    },\n    'parameters': {\n        'inp_embed_size':{\n            'values': [32, 64, 128, 256]\n        },\n        'dropout': {\n            'values': [0.2, 0.3, 0.4]\n        },\n        'lr': {\n            'values': [0.01, 0.001, 0.003]\n        },\n        'hidden_size': {\n            'values': [64, 128, 256]\n        },\n        'bidirectional': {\n            'values': ['Yes','No']\n        },\n        'batch_size': {\n            'values': [32, 64, 128]\n        },\n        'cell_type':{\n            'values': ['rnn', 'gru', 'lstm']\n        }\n    }\n}\n\nalgorithms = {\n    'rnn': nn.RNN,\n    'gru': nn.GRU,\n    'lstm': nn.LSTM\n}\n\nsweep_id = wandb.sweep(sweep=sweep_config, project='DL_Assignment3')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7XzR8BnpB3hj","outputId":"067a871d-7c2b-4560-cefa-94f661cf9e12","execution":{"iopub.status.busy":"2024-05-17T17:14:00.255680Z","iopub.execute_input":"2024-05-17T17:14:00.256529Z","iopub.status.idle":"2024-05-17T17:14:01.060203Z","shell.execute_reply.started":"2024-05-17T17:14:00.256493Z","shell.execute_reply":"2024-05-17T17:14:01.059277Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Create sweep with ID: iieguai8\nSweep URL: https://wandb.ai/arun_cs23m017/DL_Assignment3/sweeps/iieguai8\n","output_type":"stream"}]},{"cell_type":"code","source":"SOW_token = 0\nEOW_token = 1\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.letter2index = {}\n        self.letter2count = {}\n        self.index2letter = {0: \"0\", 1: \"1\"}\n        self.n_letters = 2 # Count SOW and EOW\n\n    def addWord(self, word):\n        for ch in word:\n            self.addLetter(ch)\n\n    def addLetter(self, ch):\n        if ch not in self.letter2index:\n            self.letter2index[ch] = self.n_letters\n            self.letter2count[ch] = 1\n            self.index2letter[self.n_letters] = ch\n            self.n_letters += 1\n        else:\n            self.letter2count[ch] += 1","metadata":{"id":"Et5KAVmCB3hm","execution":{"iopub.status.busy":"2024-05-17T17:14:01.062169Z","iopub.execute_input":"2024-05-17T17:14:01.062455Z","iopub.status.idle":"2024-05-17T17:14:01.069427Z","shell.execute_reply.started":"2024-05-17T17:14:01.062431Z","shell.execute_reply":"2024-05-17T17:14:01.068549Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"input_lang = Lang('eng')\noutput_lang = Lang('hin')\n\n\nx_train = pd.read_csv('/kaggle/input/aksharantar_sampled/hin/hin_train.csv', header=None) #, nrows=1000)\nx_val = pd.read_csv('/kaggle/input/aksharantar_sampled/hin/hin_valid.csv', header=None)\nx_test = pd.read_csv('/kaggle/input/aksharantar_sampled/hin/hin_test.csv', header=None)\nsz = x_train[0]","metadata":{"id":"YQtnwvwqB3hn","execution":{"iopub.status.busy":"2024-05-17T17:14:01.070460Z","iopub.execute_input":"2024-05-17T17:14:01.070704Z","iopub.status.idle":"2024-05-17T17:14:01.214406Z","shell.execute_reply.started":"2024-05-17T17:14:01.070682Z","shell.execute_reply":"2024-05-17T17:14:01.213437Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH = 50\n\ndef indexesFromWord(lang, word):\n    return [lang.letter2index[ch] for ch in word]\n\ndef tensorFromWord(lang, word):\n    indexes = indexesFromWord(lang, word)\n    indexes.append(EOW_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n\ndef wordFromTensor(lang, tensor):\n    s = \"\"\n    for i in tensor:\n        if(i.item()==1):\n            break\n        s += lang.index2letter[i.item()]\n    return s\n\ndef get_dataloader(x, input_lang, output_lang, batch_size):\n    n = len(x[0])\n    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n\n    for i in range(n):\n        input_lang.addWord(x[0][i])\n        output_lang.addWord(x[1][i])\n        inp_ids = indexesFromWord(input_lang, x[0][i])\n        tgt_ids = indexesFromWord(output_lang, x[1][i])\n        inp_ids.append(EOW_token)\n        tgt_ids.append(EOW_token)\n        input_ids[i, :len(inp_ids)] = inp_ids\n        target_ids[i, :len(tgt_ids)] = tgt_ids\n\n    data = TensorDataset(torch.LongTensor(input_ids).to(device),\n                               torch.LongTensor(target_ids).to(device))\n\n    sampler = RandomSampler(data)\n    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n    return dataloader","metadata":{"id":"1weSrUOPB3ho","execution":{"iopub.status.busy":"2024-05-17T17:14:01.215588Z","iopub.execute_input":"2024-05-17T17:14:01.215868Z","iopub.status.idle":"2024-05-17T17:14:01.226962Z","shell.execute_reply.started":"2024-05-17T17:14:01.215845Z","shell.execute_reply":"2024-05-17T17:14:01.226018Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, config, input_size):\n        super(EncoderRNN, self).__init__()\n\n        self.embedding = nn.Embedding(input_size, config.inp_embed_size)\n        self.algo = algorithms[config.cell_type](config.inp_embed_size, config.hidden_size, batch_first=True)\n        self.dropout = nn.Dropout(config.dropout)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        output, hidden = self.algo(embedded)\n        return output, hidden","metadata":{"id":"VBc-k6WEB3hq","execution":{"iopub.status.busy":"2024-05-17T17:14:01.228143Z","iopub.execute_input":"2024-05-17T17:14:01.228410Z","iopub.status.idle":"2024-05-17T17:14:01.236019Z","shell.execute_reply.started":"2024-05-17T17:14:01.228388Z","shell.execute_reply":"2024-05-17T17:14:01.235245Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hidden_size):\n        super(Attention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze(2).unsqueeze(1)\n        weights = F.softmax(scores, dim=-1)\n        context = torch.bmm(weights, keys)\n        return context, weights\n\nclass AttnDecoderRNN(nn.Module):\n    def __init__(self, config, output_size):\n        super(AttnDecoderRNN, self).__init__()\n        self.dropout_p = config.dropout\n        hidden_size = config.hidden_size\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.attention = Attention(hidden_size)\n        self.algo = algorithms[config.cell_type](hidden_size + hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(self.dropout_p)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOW_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n        attentions = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            decoder_outputs.append(decoder_output)\n            attentions.append(attn_weights)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        attentions = torch.cat(attentions, dim=1)\n\n        return decoder_outputs, decoder_hidden, attentions\n\n\n    def forward_step(self, input, hidden, encoder_outputs):\n        embedded =  self.dropout(self.embedding(input))\n\n        query = hidden.permute(1, 0, 2)\n        context, attn_weights = self.attention(query, encoder_outputs)\n        input_gru = torch.cat((embedded, context), dim=2)\n\n        output, hidden = self.algo(input_gru, hidden)\n        output = self.out(output)\n\n        return output, hidden, attn_weights","metadata":{"id":"vJOB4IXMB3hq","execution":{"iopub.status.busy":"2024-05-17T17:14:01.237171Z","iopub.execute_input":"2024-05-17T17:14:01.237513Z","iopub.status.idle":"2024-05-17T17:14:01.256333Z","shell.execute_reply.started":"2024-05-17T17:14:01.237464Z","shell.execute_reply":"2024-05-17T17:14:01.255441Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion, batch_size, teacher_forcing = True):\n\n    total_loss = 0\n    correct = 0\n    all_preds=[]\n    all_labels=[]\n    k = 0\n\n    for data in dataloader:\n        input_tensor, target_tensor = data\n\n        target_tensor2 = None\n        if (teacher_forcing):\n            target_tensor2 = target_tensor\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n\n        decoder_outputs, _, attentions = decoder(encoder_outputs, encoder_hidden, target_tensor2)\n\n        outputs = decoder_outputs.view(-1, decoder_outputs.size(-1))\n        labels = target_tensor.view(-1)\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        total_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n\n        i = 0\n        while (i < batch_size * MAX_LENGTH):\n            j = 0\n            while (j < MAX_LENGTH):\n                if(predicted[i+j] != labels[i+j]):\n                    break\n                j+=1\n            if(j==MAX_LENGTH):\n                correct += 1\n            i += MAX_LENGTH\n        k += batch_size\n\n        if(k%6400==0):\n            print(k, loss.item(), correct)\n            print(wordFromTensor(input_lang, input_tensor[0]), wordFromTensor(output_lang, target_tensor[0]), wordFromTensor(output_lang, predicted[:45]))\n            \n    return total_loss / len(dataloader), correct / k","metadata":{"id":"nlZRufH6B3hs","execution":{"iopub.status.busy":"2024-05-17T17:14:01.257442Z","iopub.execute_input":"2024-05-17T17:14:01.257782Z","iopub.status.idle":"2024-05-17T17:14:01.270281Z","shell.execute_reply.started":"2024-05-17T17:14:01.257742Z","shell.execute_reply":"2024-05-17T17:14:01.269497Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def show_attention(input_sentence, output_words, attentions):\n    # Convert list of attention weights to a 2D array\n    attentions = np.array(attentions)\n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(attentions[:len(output_words), :len(input_sentence)],\n                xticklabels=input_sentence, yticklabels=output_words,\n                cmap='viridis', ax=ax)\n    plt.xlabel('Input Sentence')\n    plt.ylabel('Output Sentence')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:14:01.273260Z","iopub.execute_input":"2024-05-17T17:14:01.273581Z","iopub.status.idle":"2024-05-17T17:14:01.283216Z","shell.execute_reply.started":"2024-05-17T17:14:01.273548Z","shell.execute_reply":"2024-05-17T17:14:01.282119Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def train(train_dataloader, val_dataloader, test_dataloader, encoder, decoder, n_epochs, config):\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=config.lr)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=config.lr)\n    criterion = nn.NLLLoss()\n\n    for epoch in range(1, n_epochs + 1):\n        print(epoch)\n        loss, acc = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, config.batch_size)\n        print(\"Train: accuracy:\", acc, \"loss:\", loss)\n        if(acc<0.01 and epoch>=15):\n            break\n        wandb.log({'train_accuracy': acc})\n        wandb.log({'train_loss': loss})\n        val_loss, val_acc = train_epoch(val_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, config.batch_size, teacher_forcing=False)\n        print(\"Validation: accuracy:\", val_acc, \"Loss:\", val_loss, \"\\n\")\n        wandb.log({'val_accuracy': val_acc})\n        wandb.log({'val_loss': val_loss})\n    \n    test_loss, test_acc = train_epoch(test_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, config.batch_size, teacher_forcing=False)\n    print(\"Test: accuracy:\", test_acc, \"Loss: \", test_loss, \"\\n\")","metadata":{"id":"LCJjy74IB3ht","execution":{"iopub.status.busy":"2024-05-17T17:14:01.284422Z","iopub.execute_input":"2024-05-17T17:14:01.284734Z","iopub.status.idle":"2024-05-17T17:14:01.297457Z","shell.execute_reply.started":"2024-05-17T17:14:01.284706Z","shell.execute_reply":"2024-05-17T17:14:01.296504Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"num_epochs = 25\n\nbest_config = {\n    'method': 'bayes', \n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'inp_embed_size':{\n            'values': [32]\n        },\n        'dropout': {\n            'values': [0.2]\n        },\n        'lr': {\n            'values': [0.001]\n        },\n        'hidden_size': {\n            'values': [256]\n        },\n        'bidirectional': {\n            'values': ['No']\n        },\n        'batch_size': {\n            'values': [128]\n        },\n        'cell_type':{\n            'values': ['gru']\n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep=best_config, project='DL_Ass3')\n\ndef main():\n    with wandb.init() as run:\n#         wandb.run.name =\n        train_dataloader = get_dataloader(x_train, input_lang, output_lang, wandb.config.batch_size)\n        val_dataloader = get_dataloader(x_val, input_lang, output_lang, wandb.config.batch_size)\n        test_dataloader = get_dataloader(x_test, input_lang, output_lang, wandb.config.batch_size)\n        encoder = EncoderRNN(wandb.config, input_lang.n_letters).to(device)\n        decoder = AttnDecoderRNN(wandb.config, output_lang.n_letters).to(device)\n        print(input_lang.n_letters, output_lang.n_letters)\n        train(train_dataloader, val_dataloader, test_dataloader, encoder, decoder, num_epochs, wandb.config)\n        encoder.eval()\n        decoder.eval()\n        evaluate(encoder, decoder)\n\nwandb.agent(sweep_id, function=main, count=1) # calls main function for count number of times.\nwandb.finish()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zKkXOUNKB3ht","outputId":"98f4d881-7fa7-4906-933a-fd92a5fc1e3b","execution":{"iopub.status.busy":"2024-05-17T17:14:01.298638Z","iopub.execute_input":"2024-05-17T17:14:01.298902Z","iopub.status.idle":"2024-05-17T17:46:34.509984Z","shell.execute_reply.started":"2024-05-17T17:14:01.298879Z","shell.execute_reply":"2024-05-17T17:46:34.509132Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Create sweep with ID: 05pksl1i\nSweep URL: https://wandb.ai/arun_cs23m017/DL_Ass3/sweeps/05pksl1i\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: brafl68b with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: No\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinp_embed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m017\u001b[0m (\u001b[33marun_cs23m017\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_171404-brafl68b</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/arun_cs23m017/DL_Ass3/runs/brafl68b' target=\"_blank\">rose-sweep-1</a></strong> to <a href='https://wandb.ai/arun_cs23m017/DL_Ass3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/arun_cs23m017/DL_Ass3/sweeps/05pksl1i' target=\"_blank\">https://wandb.ai/arun_cs23m017/DL_Ass3/sweeps/05pksl1i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/arun_cs23m017/DL_Ass3' target=\"_blank\">https://wandb.ai/arun_cs23m017/DL_Ass3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/arun_cs23m017/DL_Ass3/sweeps/05pksl1i' target=\"_blank\">https://wandb.ai/arun_cs23m017/DL_Ass3/sweeps/05pksl1i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/arun_cs23m017/DL_Ass3/runs/brafl68b' target=\"_blank\">https://wandb.ai/arun_cs23m017/DL_Ass3/runs/brafl68b</a>"},"metadata":{}},{"name":"stdout","text":"28 67\n1\n6400 0.5879917144775391 0\nbamhrauli बमरौली साााा\n12800 0.4968850016593933 0\nchhatrarajaniti छात्रराजनीति सार्रा्\n19200 0.49629971385002136 0\nnamki नमकी सिा्\n25600 0.4747169613838196 0\ngiltiyaan गिल्टियाँ सुल्यिया\n32000 0.42543068528175354 0\nhibernation हाइबर्नेशन सिरंर्यिं्\n38400 0.4174657464027405 0\npedamma पेदाम्मा साल्लाय\n44800 0.3811451196670532 0\nkrenman क्रेनमैन रररान्ान\n51200 0.38597580790519714 1\ndaanye दाँये नानगां000000000000000000000000000000000000000\nTrain: accuracy: 1.953125e-05 loss: 0.5008761431276798\nValidation: accuracy: 0.001220703125 Loss: 0.49657717254012823 \n\n2\n6400 0.2875199615955353 33\nyavishesh याविशेष अासिसे\n12800 0.22325775027275085 217\nmahilavargachi महिलावर्गाची महिलववर्वीची\n19200 0.18409422039985657 599\nmargatahi मार्गातही मररगतततिि\n25600 0.1704285442829132 1195\nisrarul इसरारुल इसरारुल\n32000 0.15305383503437042 1906\nkaydon कायदों कायोों\n38400 0.1379275768995285 2779\nkachiguda काचीगुड़ा काचिगुड़ा\n44800 0.1391189694404602 3728\nmanita मनिता मािता\n51200 0.12187753617763519 4775\nniralambata निरालंबता निरालमबता\nTrain: accuracy: 0.09326171875 loss: 0.18609928116202354\nValidation: accuracy: 0.1103515625 Loss: 0.3366152308881283 \n\n3\n6400 0.12647953629493713 901\nchinzon चिंजों चिनजों\n12800 0.09945935010910034 2029\nshuguang शुगुआंग शुगुनंग\n19200 0.10077772289514542 3283\ntiroda तिरोडा तिरोद़\n25600 0.10522489249706268 4629\nhosing होउसिन्ग् होसजिंगग\n32000 0.09515121579170227 5976\ndungi ढुंगी दुगगी\n38400 0.09230294823646545 7366\ndhakeliye धकेलिये धकेलिये\n44800 0.08306602388620377 8812\nayamon अयामों अयममों\n51200 0.08199433982372284 10223\nabhibhaashan अभिभाषण अभिभाषा\nTrain: accuracy: 0.19966796875 loss: 0.10557647190988063\nValidation: accuracy: 0.16259765625 Loss: 0.31060855742543936 \n\n4\n6400 0.08924662321805954 1222\nbhoopatiapane भूपतिअपने भूपतियपने\n12800 0.08852910250425339 2795\nmccum मैक्कम मेक्सम\n19200 0.07217440009117126 4362\nspermicides स्पर्मिसाइडस स्परममिक्इड\n25600 0.08228085190057755 6026\nmahalat महालात महालतत\n32000 0.07876256853342056 7652\nkumshet कुमशेत कुमशेत\n38400 0.08014249056577682 9351\ngoofa गुफा गूफा\n44800 0.07585087418556213 11048\nnimnabad निमनाबाद निमनाबाद\n51200 0.07969696074724197 12802\nkanglo कंगलो कंगलो\nTrain: accuracy: 0.2500390625 loss: 0.08748035173863172\nValidation: accuracy: 0.213134765625 Loss: 0.2810567761771381 \n\n5\n6400 0.086333729326725 1471\nsrinivasula श्रीनिवासुल श्रिनिवासुला000000000000000000000000000000000\n12800 0.07380184531211853 3330\nshockers शॉकर्स शोकर्स\n19200 0.07533363997936249 5143\nchhedibir छेड़ीबीर छेड़िबिर\n25600 0.07129520177841187 7030\nnaffa नफ्फा नफ्फा\n32000 0.07200294733047485 8978\nparbati पर्वती परबबती\n38400 0.07893539220094681 10919\nsadgrantho सद्ग्रंथो सदगग्रंथो\n44800 0.06388729065656662 12837\nsanketarup संकेतरूप संकेतरूप\n51200 0.07243399322032928 14775\nnitul नितुल निटुल\nTrain: accuracy: 0.28857421875 loss: 0.07716990080662071\nValidation: accuracy: 0.21923828125 Loss: 0.26964442897588015 \n\n6\n6400 0.07249476760625839 1553\nllipytaron लिप्यन्तरण ल्प्याररोो\n12800 0.07406753301620483 3481\nbhainspalak भैंसपालक भैंस्ालक\n19200 0.06398176401853561 5469\nbhovon भोवों भोवों\n25600 0.07218993455171585 7577\nnankhadi ननखड़ी नंखड़ी\n32000 0.06207907199859619 9657\nmarkundi मरकुंडी मरकुंडी\n38400 0.06871213763952255 11754\ndepositor डिपोजिटर डिपोसिटर\n44800 0.060872867703437805 13798\nmavaale मवाले मााले\n51200 0.06746447086334229 15877\nanyath अन्यथ अन्यथ\nTrain: accuracy: 0.31009765625 loss: 0.0716701087076217\nValidation: accuracy: 0.232177734375 Loss: 0.27778253704309464 \n\n7\n6400 0.06207464635372162 1725\nmaryadapriya मर्यादाप्रिय मा्यददपप्रिय\n12800 0.06122172251343727 3815\nbebahara बेबहरा बेबहाा\n19200 0.05948992818593979 5892\nyulianova यूलियानोवा युलियानोवा\n25600 0.058012548834085464 7996\ntrikumji त्रिकुमजी त्रिकुमजी\n32000 0.053620845079422 10237\ntsingua त्सिंगुआ त्सिंगुआ\n38400 0.05530690774321556 12485\njfa जेएफए जेएफए\n44800 0.06820908188819885 14662\ngaanvanivaasi गाँवनिवासी गाँवनीवासी\n51200 0.06057417392730713 16833\nlipyukti लिप्युक्ति लिप्युक्ति\nTrain: accuracy: 0.32876953125 loss: 0.06758331621065736\nValidation: accuracy: 0.24560546875 Loss: 0.25994268897920847 \n\n8\n6400 0.06548096239566803 1895\nshulan शूलां शुलनन\n12800 0.07049985975027084 4113\nkiramam किरामाम किरामाम\n19200 0.06275111436843872 6320\nmastishak मस्तिषक मस्तिशक\n25600 0.06134014576673508 8547\nubhayaatmak उभयात्मक उभाात्मक\n32000 0.05857003852725029 10791\nvedavalli वेदवल्ली वेदाल्ली\n38400 0.055136870592832565 13075\nmehdia मेहदिया मेहदिया\n44800 0.049554403871297836 15321\ngovanardhannath गोवनर्धननाथ गोवनर्धन्ाथ\n51200 0.06242050230503082 17639\nsamjamein समजमें समजमें\nTrain: accuracy: 0.34451171875 loss: 0.06407273989170789\nValidation: accuracy: 0.26513671875 Loss: 0.24773404886946082 \n\n9\n6400 0.06873404234647751 1977\nprayagraj प्रयागराज प्रयाग्ाज\n12800 0.06128566339612007 4278\njyanchyapasoon ज्यांच्यापासून ज्यांच्यापासून\n19200 0.05596248805522919 6616\ndiwaswapnon दिवास्वप्नों दिवासववपननों\n25600 0.06623440235853195 8952\nnainavati नैनावती नैनववती\n32000 0.05415833368897438 11380\nfabrica फैब्रिका फेब्रिका\n38400 0.05295872688293457 13713\ncerebrus सेरेब्रस सररेब्रस\n44800 0.0548846535384655 16051\nmangirish मांगिरिश मंंगिरिश\n51200 0.06169223412871361 18439\nforegone फोरगोन फोरेोने00000000000000000000000000000000000000\nTrain: accuracy: 0.36013671875 loss: 0.061354329101741316\nValidation: accuracy: 0.274169921875 Loss: 0.2385946516878903 \n\n10\n6400 0.060260891914367676 2020\ngobar गोबार गोबार\n12800 0.05964941531419754 4403\nnavonmeshk नवोन्मेष्क नेों्मेश्क\n19200 0.05031445994973183 6737\nkholab खोलब खोलब\n25600 0.0693720132112503 9142\nthirst प्यास थीररर्000000000000000000000000000000000000000\n32000 0.053346890956163406 11605\nsuryagrah सूर्यग्रह सुर्यग्रह\n38400 0.05651148781180382 14120\nbujhe बुझें बुझे\n44800 0.05317266285419464 16570\nbalclub बालक्लब बैलक्लब\n51200 0.04866062104701996 19003\nwenbaum वेनबाम वेनबॉउ\nTrain: accuracy: 0.37115234375 loss: 0.059783362792804835\nValidation: accuracy: 0.2900390625 Loss: 0.23151982575654984 \n\n11\n6400 0.05366623029112816 2140\ndashahatpurna दशहतपूर्ण दशातपुर्ण\n12800 0.050286974757909775 4669\nmewal मेवाल मेवाल\n19200 0.056205421686172485 7228\nhypothermia हाइपोथार्मिया हाइपोथेरममिया\n25600 0.05316811427474022 9797\nigarassu इगारासु इगररसस्\n32000 0.0591253861784935 12272\npalodada पालोदड़ा पललोदा़ा\n38400 0.052561089396476746 14761\ndegrasse डीग्रास डेग्रेस\n44800 0.043491411954164505 17218\nupachari उपचारी उपचररी\n51200 0.048616670072078705 19706\nhublot हबलॉट हुलोट\nTrain: accuracy: 0.3848828125 loss: 0.05710867105983198\nValidation: accuracy: 0.303466796875 Loss: 0.22618887620046735 \n\n12\n6400 0.06152915582060814 2206\npradarshani प्रदर्शनि प्रदर्शनी\n12800 0.05679835006594658 4753\nintjam इंतजाम इंत्मम\n19200 0.05034460127353668 7314\nsameekshaadi समीक्षादि समीक्षादी\n25600 0.052609194070100784 9894\ndivasashch दिवसाश्च दिवसशश्च\n32000 0.06627989560365677 12482\ngadchiroli गढचिरौली गड़िरोली\n38400 0.05201484635472298 15031\nlakkho लक्खो लक्खो\n44800 0.0433226153254509 17615\nudmf यूडीएमएफ यूडीएमएफ\n51200 0.05682786926627159 20163\ndavaluri डैवुलुरी दववालुरी\nTrain: accuracy: 0.39380859375 loss: 0.05539613081142306\nValidation: accuracy: 0.3203125 Loss: 0.2207093690522015 \n\n13\n6400 0.05886431783437729 2265\npragyananand प्रज्ञानानंद प्रज्ञानाननद\n12800 0.05222872644662857 4906\ngabriella गेब्रिएला गेब्रियला\n19200 0.046125832945108414 7558\ncorumba कोरूम्बा कोर्म्बा\n25600 0.04762707278132439 10200\nmicrometer मायक्रोमीटर माइक्रोमीटर\n32000 0.06075477600097656 12804\ngherahi घेराही घेरहही\n38400 0.05003673583269119 15432\nchinjorig चिन्जोरिग चिंजजोरिग\n44800 0.04745037108659744 18110\nvijaatiyon विजातियों विजातियों\n51200 0.05138002336025238 20692\nvetnas वेतनास वेटनास\nTrain: accuracy: 0.404140625 loss: 0.0538348429184407\nValidation: accuracy: 0.327880859375 Loss: 0.2118480857461691 \n\n14\n6400 0.04442906007170677 2366\nlunawada लूनवाडा लुनााड़\n12800 0.048178620636463165 5082\nmyakre म्याक्रे मायाक्रे\n19200 0.0527091845870018 7825\ncharlize शार्लीज़ चार्लिज\n25600 0.050430383533239365 10547\nbaetthney बैठने बैठने\n32000 0.05079011619091034 13238\ncrappy क्रैपी क्रेपी\n38400 0.05086177960038185 15899\nparinishpanna परिनिष्पन्न परिणिष्पन्न\n44800 0.06636622548103333 18526\nspringon स्प्रिंगों स्प्रिंगोन\n51200 0.04913146048784256 21133\nbaadegaanv बाड़ेगांव बाड़ेगांव\nTrain: accuracy: 0.41275390625 loss: 0.05258338806219399\nValidation: accuracy: 0.31494140625 Loss: 0.22001311369240284 \n\n15\n6400 0.05153420940041542 2420\nnirajala निरजला निराला\n12800 0.043887633830308914 5091\nchavreshwari चव्रेश्वरी चा्रेश्वरी\n19200 0.05157334357500076 7871\ninralment इनरालमेंट इनरालमेंट\n25600 0.05894974246621132 10676\nbadhaiyega बढ़ाइएगा बढ़ायएगा\n32000 0.05719919502735138 13413\ngantok गंटोक गंटोक\n38400 0.05242468789219856 16082\nbachelard बैचलर्ड बैचेर्ड\n44800 0.048760510981082916 18781\nukshan उक्षण उक्षण\n51200 0.0520135872066021 21522\nscandles स्कैण्डल्स स्कैं्डल्स\nTrain: accuracy: 0.4203515625 loss: 0.05160388336516917\nValidation: accuracy: 0.337890625 Loss: 0.2150054587982595 \n\n16\n6400 0.051072970032691956 2441\nshimazu शिमाज़ु शिमाजुू\n12800 0.041497014462947845 5233\naffliated एफलिएटेड एफ्ाएटेड\n19200 0.04954478144645691 8013\nmenghar मेंघर मेंघर\n25600 0.04472729563713074 10879\nkevi केवी केवी\n32000 0.05234912782907486 13743\ndoru डूरू डोरू\n38400 0.05201277881860733 16595\nhaathon हाथों हाथों\n44800 0.05223001167178154 19317\nunpalabdh उनपलब्ध उनपलब्ध\n51200 0.04421331360936165 22163\noae ओएई ओएएए00000000000000000000000000000000000000000\nTrain: accuracy: 0.43287109375 loss: 0.049839896894991395\nValidation: accuracy: 0.37109375 Loss: 0.19647318730130792 \n\n17\n6400 0.04633663594722748 2429\ndorababu दोराबाबू दोराबाबू\n12800 0.04256352409720421 5283\nfreyod फ्रेयोड फ्रेयोड\n19200 0.04126642271876335 8185\nchinchavadparyant चिंचवडपर्यंत चिंचवदपा्यंत\n25600 0.04266541078686714 10975\nregency रेजेंसी रेजेंसी\n32000 0.047488659620285034 13859\npoonchhdaar पूंछदार पूँछदार\n38400 0.046851545572280884 16743\nvyaayaamon व्यायामों व्यायामों\n44800 0.04475067928433418 19581\ngillipsy गिलिप्सी गिलिप्सी\n51200 0.044288519769907 22436\nthermoberic थर्मोबेरिक थर्मोबेरिक\nTrain: accuracy: 0.438203125 loss: 0.04928588793613017\nValidation: accuracy: 0.386474609375 Loss: 0.19498685747385025 \n\n18\n6400 0.04741939902305603 2642\nsamajhabhari समझभरी समझभरी\n12800 0.043342385441064835 5622\nchelahi चेलाही चेलाही\n19200 0.05294095352292061 8548\nplateletschee प्लेटलेटस्ची प्लेटलेटस्की\n25600 0.04747520014643669 11430\njulaniyapura जुलानियापुरा जुलननियापुरा\n32000 0.040199752897024155 14324\nlorki लोरकी लोरकी\n38400 0.03872057422995567 17191\ndukli डुकली दुकली\n44800 0.04062674939632416 20112\nchipti चिपटी चिपटी\n51200 0.03869772329926491 22931\nnarsee नर्सी नरससी\nTrain: accuracy: 0.44787109375 loss: 0.047711834358051416\nValidation: accuracy: 0.38330078125 Loss: 0.18834214098751545 \n\n19\n6400 0.04375073313713074 2628\naney एनी एनी\n12800 0.04015549644827843 5607\nsuhagiya सुहागिया सुहागिया\n19200 0.050821684300899506 8533\nkoiripur कौरीपुर कोइीपुर\n25600 0.04453858733177185 11498\nchirparichith चिरपरिचित चिरपरिचित\n32000 0.04463709518313408 14450\nmadlani मदलानी मदलानी\n38400 0.04260172322392464 17381\ninskip इन्सकिप इंससकिप\n44800 0.04081598296761513 20358\nasatayapit असत्यापित असतायायित\n51200 0.04563082754611969 23345\nmajidganj मजीदगंज मजीदगंज\nTrain: accuracy: 0.45595703125 loss: 0.04669563496485352\nValidation: accuracy: 0.37939453125 Loss: 0.1921949959360063 \n\n20\n6400 0.04629683867096901 2505\namdoskar आमडोसकर आम्ोसकर\n12800 0.03826415538787842 5522\npratidhaaran प्रतिधारण प्रतिधारण\n19200 0.04740471392869949 8546\nnetron नेत्रों नेत्रों\n25600 0.03870810195803642 11568\nmutwaji मुतवाजी मुतवाजी\n32000 0.039304956793785095 14547\nvichardharna विचारधारणा विचारधररणा\n38400 0.039913810789585114 17538\npramukhroop प्रमुखरूप प्रमुख्ूप\n44800 0.040557313710451126 20498\nshaleen शालीन शललीन\n51200 0.03999970480799675 23501\nalichen अलिचेन अलीचेन\nTrain: accuracy: 0.45900390625 loss: 0.04580465574748814\nValidation: accuracy: 0.407958984375 Loss: 0.1844152701087296 \n\n21\n6400 0.04532163590192795 2712\nmarise मारिसे मेरिस\n12800 0.037580475211143494 5765\nabhivanchiton अभिवंचितों अभिवनचितों\n19200 0.04285300150513649 8781\naspust अस्पस्ट एस्पस्ट\n25600 0.04416269436478615 11840\ndanavelou धनवेलु डनवेलू\n32000 0.041722334921360016 14835\naampaathak आमपाठक आम्ाठक\n38400 0.03876107931137085 17862\ndilvaana दिलवाना दिलवाना\n44800 0.04595884680747986 20903\npurnanagiri पूर्णनागिरी पुर्णनगगिरी\n51200 0.037458620965480804 23921\nyalappa यलप्पा यलप्पा\nTrain: accuracy: 0.46720703125 loss: 0.044860440893098714\nValidation: accuracy: 0.420654296875 Loss: 0.18053130060434341 \n\n22\n6400 0.04345260187983513 2735\nupechha उपेछा उपचचा\n12800 0.04076947271823883 5834\nnanduli नंदूली नंदूली\n19200 0.04466963931918144 8883\nthirkanon थिरकनों ठिरकाों\n25600 0.04082103818655014 12001\nhypotensive हाईपोटेंसिव हाइपोटेंसिव\n32000 0.04370056465268135 15141\nbholandu भोलन्दु भोला्दु\n38400 0.046884022653102875 18237\nsemec सेमेक सेमेक\n44800 0.04784943535923958 21292\nevini एविनी एविनी\n51200 0.050971463322639465 24346\nbreethless ब्रीथलेस ब्रीथल्स\nTrain: accuracy: 0.4755078125 loss: 0.04384287264198065\nValidation: accuracy: 0.42529296875 Loss: 0.1745178725104779 \n\n23\n6400 0.040240343660116196 2760\ngukaarane गुकारने गुकारने\n12800 0.03838382288813591 5868\nbaarne बारने बारने\n19200 0.03511825576424599 8981\njingjimbar जिंगजिंबार जिंगजीमबरर\n25600 0.03973288834095001 12075\nkaaryavritt कार्यवृत्त कार्यवृत्त\n32000 0.04323328658938408 15214\nmisma मिसमा मिस्ा\n38400 0.042664650827646255 18332\nramrup रामरुप रामरूप\n44800 0.04450283944606781 21466\nbachchekampaneesah बच्चेकंपनीसह बच्चेकंपनीसह\n51200 0.05522124469280243 24551\nkshetraache क्षेत्राचे क्षेत्राचे\nTrain: accuracy: 0.47951171875 loss: 0.043013988891616464\nValidation: accuracy: 0.423095703125 Loss: 0.17441944079473615 \n\n24\n6400 0.035027313977479935 2762\nhalderpur हलदरपुर हलदरपुर\n12800 0.045337751507759094 5986\nshakkarmandori शक्करमंदोरी शक्करमंडोरी\n19200 0.04057547450065613 9226\nparatkundiya परतकुण्डिया परतकुं्डीया\n25600 0.04099210351705551 12487\nrulad रुलद रुला\n32000 0.04511655494570732 15648\ndalbandin दालबंदीन दललबंदीन\n38400 0.040049292147159576 18769\nsucson सक्सन सूससन\n44800 0.03760012984275818 21915\nchhawana छावना छववना\n51200 0.03148516267538071 25060\ntumsab तुमसब तुमसा\nTrain: accuracy: 0.489453125 loss: 0.042469635405577716\nValidation: accuracy: 0.4287109375 Loss: 0.18367588194087148 \n\n25\n6400 0.04067637771368027 2784\nfortsque फोर्ट्स्क्यू फोर्ट्स्क्यू\n12800 0.03698621690273285 5932\nbatiyawa बतियावा बतियावा\n19200 0.03530929237604141 9205\npangatiya पंगतिया पंगतिया\n25600 0.03824932500720024 12535\nmanavtala मानवतला मानवतला\n32000 0.03900808095932007 15734\ngahaari गहारी गहारी\n38400 0.048083219677209854 19013\nvaradar वरदर वरदर\n44800 0.04123251512646675 22216\nhokan होकन होकन\n51200 0.04439590871334076 25399\nhashid हशीद हाीद\nTrain: accuracy: 0.49607421875 loss: 0.04123093197587877\nValidation: accuracy: 0.446533203125 Loss: 0.16626597405411303 \n\nTest: accuracy: 0.2119140625 Loss:  0.2259071683511138 \n\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_34/3224865044.py\", line 48, in main\n    evaluate(encoder, decoder)\nNameError: name 'evaluate' is not defined\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▂▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.49607</td></tr><tr><td>train_loss</td><td>0.04123</td></tr><tr><td>val_accuracy</td><td>0.44653</td></tr><tr><td>val_loss</td><td>0.16627</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rose-sweep-1</strong> at: <a href='https://wandb.ai/arun_cs23m017/DL_Ass3/runs/brafl68b' target=\"_blank\">https://wandb.ai/arun_cs23m017/DL_Ass3/runs/brafl68b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_171404-brafl68b/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run brafl68b errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/3224865044.py\", line 48, in main\n    evaluate(encoder, decoder)\nNameError: name 'evaluate' is not defined\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run brafl68b errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/3224865044.py\", line 48, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     evaluate(encoder, decoder)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m NameError: name 'evaluate' is not defined\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}